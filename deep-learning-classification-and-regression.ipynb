{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":78156,"sourceType":"datasetVersion","datasetId":44109,"isSourceIdPinned":false}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import kagglehub\nimport os\nimport glob\nimport pandas as pd\n\npath = kagglehub.dataset_download(\"jangedoo/utkface-new\")\nprint(\"Dataset location:\", path)\n\nimage_paths = glob.glob(os.path.join(path, \"**/*.jpg\"), recursive=True)\n\ndata = []\nfor p in image_paths:\n    filename = os.path.basename(p)\n    parts = filename.split('_')\n    \n    if len(parts) >= 2:\n        try:\n            age = int(parts[0])\n            gender = int(parts[1]) # 0=Male, 1=Female\n            data.append({\"path\": p, \"age\": age, \"gender\": gender})\n        except (ValueError, IndexError):\n            continue \n\ndf = pd.DataFrame(data)\n\nprint(f\"✅ Success! Total images processed: {len(df)}\")\nprint(df.head())","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-16T06:58:28.083309Z","iopub.execute_input":"2026-02-16T06:58:28.084080Z","iopub.status.idle":"2026-02-16T07:00:15.851301Z","shell.execute_reply.started":"2026-02-16T06:58:28.084051Z","shell.execute_reply":"2026-02-16T07:00:15.850460Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport cv2\nimport random\nfrom sklearn.model_selection import train_test_split\n\ntrain_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n\ndef data_generator(df, batch_size=32, augment=False):\n    while True:\n        df_shuffled = df.sample(frac=1).reset_index(drop=True)\n        for i in range(0, len(df_shuffled), batch_size):\n            batch_df = df_shuffled.iloc[i:i+batch_size]\n            images, ages, genders = [], [], []\n            \n            for _, row in batch_df.iterrows():\n                img = cv2.imread(row['path'])\n                if img is None: continue\n                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n                img = cv2.resize(img, (200, 200))\n        \n                if augment:\n                    if random.random() > 0.5:\n                        img = cv2.flip(img, 1)\n                    angle = random.uniform(-10, 10)\n                    M = cv2.getRotationMatrix2D((100, 100), angle, 1.0)\n                    img = cv2.warpAffine(img, M, (200, 200))\n                \n                images.append(img / 255.0)\n                ages.append(row['age'])\n                genders.append(row['gender'])\n            \n            yield np.array(images), {\n                \"age_output\": np.array(ages, dtype='float32'), \n                \"gender_output\": np.array(genders, dtype='float32')\n            }\n\ntrain_gen = data_generator(train_df, augment=True)\ntest_gen = data_generator(test_df, augment=False)\n\nprint(\"✅ Augmented Pipeline Ready!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T07:01:37.583916Z","iopub.execute_input":"2026-02-16T07:01:37.584241Z","iopub.status.idle":"2026-02-16T07:01:37.608267Z","shell.execute_reply.started":"2026-02-16T07:01:37.584215Z","shell.execute_reply":"2026-02-16T07:01:37.607554Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam \n\ndef build_model():\n    inputs = Input(shape=(200, 200, 3))\n \n    x = Conv2D(32, (3, 3), activation='relu')(inputs)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D((2, 2))(x)\n    \n    x = Conv2D(64, (3, 3), activation='relu')(x)\n    x = MaxPooling2D((2, 2))(x)\n    \n    x = Conv2D(128, (3, 3), activation='relu')(x)\n    x = MaxPooling2D((2, 2))(x)\n    \n    x = Flatten()(x)\n\n    x = Dense(256, activation='relu')(x)\n    x = Dropout(0.5)(x)\n\n    gender_out = Dense(1, activation='sigmoid', name='gender_output')(x)\n\n    age_out = Dense(1, activation='relu', name='age_output')(x)\n    \n    model = Model(inputs=inputs, outputs=[age_out, gender_out])\n    return model\n\nmodel = build_model()\n\ncustom_optimizer = Adam(learning_rate=0.0001)\n\nmodel.compile(\n    optimizer=custom_optimizer,\n    loss={'age_output': 'mse', 'gender_output': 'binary_crossentropy'},\n    metrics={'age_output': 'mae', 'gender_output': 'accuracy'}\n)\n\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T07:01:43.901136Z","iopub.execute_input":"2026-02-16T07:01:43.901670Z","iopub.status.idle":"2026-02-16T07:02:01.008134Z","shell.execute_reply.started":"2026-02-16T07:01:43.901639Z","shell.execute_reply":"2026-02-16T07:02:01.007601Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\ncallbacks = [\n    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n    ModelCheckpoint('best_multi_task_model.keras', save_best_only=True)\n]\n\nhistory = model.fit(\n    train_gen,\n    steps_per_epoch=len(train_df) // 32,\n    validation_data=test_gen,\n    validation_steps=len(test_df) // 32,\n    epochs=20,\n    callbacks=callbacks\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T01:13:17.806862Z","iopub.execute_input":"2026-02-16T01:13:17.807159Z","iopub.status.idle":"2026-02-16T02:26:11.051654Z","shell.execute_reply.started":"2026-02-16T01:13:17.807134Z","shell.execute_reply":"2026-02-16T02:26:11.050852Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\ntest_images, test_labels = next(test_gen)\n\npredictions = model.predict(test_images)\npred_ages = predictions[0]\npred_genders = predictions[1]\n\nplt.figure(figsize=(20, 10))\nfor i in range(10):\n    plt.subplot(2, 5, i+1)\n    plt.imshow(test_images[i])\n\n    actual_g = \"Male\" if test_labels['gender_output'][i] == 0 else \"Female\"\n    pred_g = \"Male\" if pred_genders[i] < 0.5 else \"Female\"\n\n    actual_a = int(test_labels['age_output'][i])\n    pred_a = int(pred_ages[i][0])\n    \n    plt.title(f\"Actual: {actual_a}, {actual_g}\\nPred: {pred_a}, {pred_g}\")\n    plt.axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T07:06:15.360380Z","iopub.execute_input":"2026-02-16T07:06:15.361063Z","iopub.status.idle":"2026-02-16T07:06:18.243367Z","shell.execute_reply.started":"2026-02-16T07:06:15.361034Z","shell.execute_reply":"2026-02-16T07:06:18.242581Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save('/kaggle/working/final_augmented_age_gender_model.keras')\nprint(\"✅ Model saved in /kaggle/working/\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T07:02:25.452030Z","iopub.execute_input":"2026-02-16T07:02:25.453013Z","iopub.status.idle":"2026-02-16T07:02:25.775057Z","shell.execute_reply.started":"2026-02-16T07:02:25.452983Z","shell.execute_reply":"2026-02-16T07:02:25.774452Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing import image\n\ndef predict_my_face(img_path):\n    img = cv2.imread(img_path)\n    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n    faces = face_cascade.detectMultiScale(img_rgb, 1.3, 5)\n    \n    if len(faces) == 0:\n        print(\"❌ No face detected! Try a clearer photo with better lighting.\")\n        return\n\n    (x, y, w, h) = faces[0]\n    face_crop = img_rgb[y:y+h, x:x+w]\n\n    face_resized = cv2.resize(face_crop, (200, 200))\n    face_final = face_resized / 255.0\n    face_input = np.expand_dims(face_final, axis=0)\n\n    predictions = model.predict(face_input)\n    \n    pred_age = int(predictions[0][0][0])\n    pred_gender = \"Male\" if predictions[1][0][0] < 0.5 else \"Female\"\n    confidence = (1 - predictions[1][0][0]) if pred_gender == \"Male\" else predictions[1][0][0]\n\n    plt.imshow(face_resized)\n    plt.title(f\"Prediction: {pred_age} years old, {pred_gender}\\nConfidence: {confidence*100:.2f}%\")\n    plt.axis('off')\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T07:02:56.119116Z","iopub.execute_input":"2026-02-16T07:02:56.119676Z","iopub.status.idle":"2026-02-16T07:02:56.126302Z","shell.execute_reply.started":"2026-02-16T07:02:56.119651Z","shell.execute_reply":"2026-02-16T07:02:56.125588Z"}},"outputs":[],"execution_count":null}]}